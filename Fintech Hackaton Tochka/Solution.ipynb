{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm \n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from tqdm.notebook import tqdm\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = pd.read_csv('/Private/DataScience/Python/Fintech Hackaton Tochka/edges.csv')\n",
    "ids = pd.read_csv('/Private/DataScience/Python/Fintech Hackaton Tochka/ids.csv')\n",
    "vertices = pd.read_csv('/Private/DataScience/Python/Fintech Hackaton Tochka/vertices wth 5 neigh.csv') # preprocessed vertices with 5 KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our graph we have 1534749 vertices (nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vertices) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this step transforming our features to categorical using LabelEncoder and standardizing them using StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices['main_okved'] = vertices['main_okved'].astype(str)\n",
    "vertices['region_code'] = vertices['region_code'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "vertices['company_type'] = le.fit_transform(vertices['company_type'])\n",
    "vertices['main_okved'] = le.fit_transform(vertices['main_okved'])\n",
    "vertices['region_code'] = le.fit_transform(vertices['region_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "vertices['company_type'] = ss.fit_transform(vertices['company_type'].values.reshape(-1, 1))\n",
    "vertices['main_okved'] = ss.fit_transform(vertices['main_okved'].values.reshape(-1, 1))\n",
    "vertices['region_code'] = ss.fit_transform(vertices['region_code'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating table for results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=['id_1', 'id_2','preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.drop([\"value\",\"n_transactions\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_edges = genfromtxt('no edges.csv', delimiter=',')\n",
    "no_edges = no_edges[1:].astype(int)\n",
    "no_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_edges[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices.loc[no_edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from catboost import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# учтем то, что вершина i может быть как среди id_1, так и среди id_2\n",
    "df1 = edges[edges['id_1'] == i].reset_index()\n",
    "df2 = edges[edges['id_2'] == i].reset_index()\n",
    "\n",
    "df = df1[['id_2', 'id_1']].rename(columns={'id_1':'id_2', 'id_2':'id_1'}).append(df2[['id_1', 'id_2']])\n",
    "df['target'] = 1\n",
    "\n",
    "df = vertices.join(df.set_index('id_1')['target']).fillna(0)\n",
    "\n",
    "#training set\n",
    "'''indexes = df.loc[df.target != 1].index\n",
    "train_data = pd.DataFrame(columns=df.columns)\n",
    "#train_data\n",
    "for j in tqdm(range(round(len(df.loc[df.target == 1])*0.7))):\n",
    "    train_data = train_data.append(df.loc[random.choice(indexes)], sort=False)\n",
    "train_data = train_data.append(df.loc[df.target == 1].iloc[:round(len(df.loc[df.target == 1])*0.7)], sort=False)\n",
    "\n",
    "#evaluation set\n",
    "eval_indx = df.loc[df.target != 1].drop(train_data.index,errors='ignore').index\n",
    "eval_data = pd.DataFrame(columns=df.columns) #check number\n",
    "\n",
    "for q in tqdm(range(round(len(df.loc[df.target == 1])*0.3))):\n",
    "    eval_data = eval_data.append(df.loc[random.choice(eval_indx)], sort=False)\n",
    "eval_data = eval_data.append(df.loc[df.target == 1].iloc[round(len(df.loc[df.target == 1])*0.7):], sort=False)\n",
    "\n",
    "eval_dataset = Pool(eval_data.loc[:,'main_okved':'centrality'], eval_data['target'])'''\n",
    "\n",
    "X = df.loc[:,'main_okved':'5_nn_5']\n",
    "y = df['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# соберем датасет из всех возможных вершин\n",
    "# вершины имеющие в исходных данных ребро с i обозначим 1, остальные 0\n",
    "\n",
    "#model = CatBoostClassifier(task_type='GPU', iterations=100, eval_metric='AUC')\n",
    "# все признаки категориальные\n",
    "  \n",
    "#model = LGBMClassifier(eval_metric='AUC')\n",
    "model = XGBClassifier(objective ='binary:logistic', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_proba(X.loc[no_edges])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[no_edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preds'] = preds\n",
    "df['id_2'] = ids.id.iloc[0]\n",
    "df.drop(i, inplace=True, errors=\"ignore\")\n",
    "df.drop(edges[edges['id_2'] == i].id_1.values, inplace=True, errors=\"ignore\")\n",
    "df.drop(edges[edges['id_1'] == i].id_2.values, inplace=True, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vertices = vertices.merge(degree, how='inner', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices_orig = pd.read_csv(\"/Private/DataScience/Python/Fintech Hackaton Tochka/vert no norm 5 nbr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices_orig.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices['company_type'] = vertices_orig['company_type'].astype(str)\n",
    "vertices['main_okved'] = vertices_orig['main_okved'].astype(str)\n",
    "vertices['region_code'] = vertices_orig['region_code'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=['id_1', 'id_2','preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(ids.id):\n",
    "    # соберем датасет из всех возможных вершин\n",
    "    # вершины имеющие в исходных данных ребро с i обозначим 1, остальные 0\n",
    "    # учтем то, что вершина i может быть как среди id_1, так и среди id_2\n",
    "    df1 = edges[edges['id_1'] == i].reset_index()\n",
    "    df2 = edges[edges['id_2'] == i].reset_index()\n",
    "\n",
    "    df = df1[['id_2', 'id_1']].rename(columns={'id_1':'id_2', 'id_2':'id_1'}).append(df2[['id_1', 'id_2']])\n",
    "    df['target'] = 1\n",
    "    \n",
    "    df = vertices.join(df.set_index('id_1')['target']).fillna(0)\n",
    "\n",
    "    #training set\n",
    "    ''' indexes = df.loc[df.target != 1].index\n",
    "    train_data = pd.DataFrame(columns=df.columns)\n",
    "    #train_data\n",
    "    for j in tqdm(range(round(len(df.loc[df.target == 1])*0.7))):\n",
    "        train_data = train_data.append(df.loc[random.choice(indexes)], sort=False)\n",
    "    train_data = train_data.append(df.loc[df.target == 1].iloc[:round(len(df.loc[df.target == 1])*0.7)], sort=False)\n",
    "\n",
    "    #evaluation set\n",
    "    eval_indx = df.loc[df.target != 1].drop(train_data.index,errors='ignore').index\n",
    "    eval_data = pd.DataFrame(columns=df.columns) #check number\n",
    "    \n",
    "    for q in tqdm(range(round(len(df.loc[df.target == 1])*0.3))):\n",
    "        eval_data = eval_data.append(df.loc[random.choice(eval_indx)], sort=False)\n",
    "    eval_data = eval_data.append(df.loc[df.target == 1].iloc[round(len(df.loc[df.target == 1])*0.7):], sort=False)\n",
    "\n",
    "    eval_dataset = Pool(eval_data.loc[:,'main_okved':'5_nn_5'], eval_data['target'])\n",
    "    '''\n",
    "    X = df.loc[:,'main_okved':'5_nn_5']\n",
    "    y = df['target']\n",
    "    \n",
    "\n",
    "    model = CatBoostClassifier(task_type='GPU', iterations=100, eval_metric='AUC')\n",
    "    #model_lightgbm = LGBMClassifier(eval_metric='AUC',is_unbalance=True,boosting='gbdt')   \n",
    "    # все признаки категориальные\n",
    "\n",
    "    model.fit(X, y,cat_features=[0,1,2,3,4,5])\n",
    "    print(\"CatBoost fit ready\")\n",
    "    df = df.loc[no_edges]\n",
    "  #  df['preds_cat'] = model.predict_proba(X.loc[no_edges])[:,1]\n",
    " #   df['preds_lightgbm'] = model_lightgbm.predict_proba(X.loc[no_edges])[:,1]\n",
    "#    df['preds'] = df['preds_lightgbm']+df['preds_cat']\n",
    "    df['preds'] = model.predict_proba(X.loc[no_edges])[:,1]\n",
    "\n",
    "    df['id_2'] = i\n",
    "    df.drop(i, inplace=True, errors=\"ignore\")\n",
    "    df.drop(edges[edges['id_2'] == i].id_1.values, inplace=True, errors=\"ignore\")\n",
    "    df.drop(edges[edges['id_1'] == i].id_2.values, inplace=True, errors=\"ignore\")\n",
    "    \n",
    "    \n",
    "    # возьмем первую 1000 предсказанных ребер, исключив те, про которые мы уже знали\n",
    "    #res = \n",
    "    #res.columns = ['id_1', 'id_2']\n",
    "    \n",
    "    result = result.append(df[df['target'] != 1].sort_values(by='preds', ascending=False).iloc[:3000].reset_index()[['id', 'id_2','preds']], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_new.to_csv('/Private/DataScience/Python/Fintech Hackaton Tochka/result_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.loc[result['id'] != result['id_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('/Private/DataScience/Python/Fintech Hackaton Tochka/res.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('/Private/DataScience/Python/Fintech Hackaton Tochka/results 20k only sum.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(by='preds', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['id_1'] = result['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.loc['id_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.drop(['id','preds'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_new = pd.DataFrame(np.sort(result[['id_1','id_2']].values, axis=1), columns=result[['id_1','id_2']].columns).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_new.id_1 = result_new.id_1.astype(int)\n",
    "result_new.id_2 = result_new.id_2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_new.iloc[:100000].to_csv('/Private/DataScience/Python/Fintech Hackaton Tochka/result_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.from_pandas_edgelist(edges, source='id_1', target='id_2') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_dict = dict(g.degree(g.nodes()))\n",
    "nx.set_node_attributes(g, degree_dict, 'degree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "degrees = []\n",
    "for j in tqdm(vertices.index):\n",
    "    try:\n",
    "        degrees.append([j,g.nodes[j]['degree']])\n",
    "    except:\n",
    "    #print('Error',i)\n",
    "        errors.append(j)\n",
    "degree = pd.DataFrame(degrees, columns=['id','degree'])\n",
    "degree.set_index('id', inplace=True)\n",
    "vertices = vertices.merge(degree, how='inner', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices['degree'] = ss.fit_transform(vertices['degree'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time nbrs=NearestNeighbors(n_neighbors=4, algorithm='kd_tree', n_jobs=4).fit(np.array(vertices.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = nbrs.kneighbors(np.array(vertices.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices['1_nearest_neigbour'] = [indices[r][0] for r in range(len(vertices.index))]\n",
    "vertices['2_nearest_neigbour'] = [indices[r][1] for r in range(len(vertices.index))]\n",
    "vertices['3_nearest_neigbour'] = [indices[r][2] for r in range(len(vertices.index))]\n",
    "vertices['4_nearest_neigbour'] = [indices[r][3] for r in range(len(vertices.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices.to_csv('/Private/DataScience/Python/Fintech Hackaton Tochka/vertices_normalized with neighbours reworked.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices['1_nearest_neigbour'] = le.fit_transform(vertices['1_nearest_neigbour'])\n",
    "vertices['2_nearest_neigbour'] = le.fit_transform(vertices['2_nearest_neigbour'])\n",
    "vertices['3_nearest_neigbour'] = le.fit_transform(vertices['3_nearest_neigbour'])\n",
    "vertices['4_nearest_neigbour'] = le.fit_transform(vertices['4_nearest_neigbour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = edges[edges['id_1'] == ids.id.iloc[0]].reset_index()\n",
    "df2 = edges[edges['id_2'] == ids.id.iloc[0]].reset_index()\n",
    "\n",
    "df = df1[['id_2', 'id_1']].rename(columns={'id_1':'id_2', 'id_2':'id_1'}).append(df2[['id_1', 'id_2']])\n",
    "df['target'] = 1\n",
    "\n",
    "df = vertices.join(df.set_index('id_1')['target']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['main_okved', 'region_code', 'company_type','degree','1_nearest_neigbour','2_nearest_neigbour','3_nearest_neigbour','4_nearest_neigbour']]\n",
    "y = df['target']\n",
    "model = CatBoostClassifier(task_type='GPU',iterations=100, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)\n",
    "preds = model.predict_proba(X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['main_okved', 'region_code', 'company_type','degree','1_nearest_neigbour','2_nearest_neigbour','3_nearest_neigbour','4_nearest_neigbour']]\n",
    "y = df['target']\n",
    "model = CatBoostClassifier(task_type='GPU',iterations=100, verbose=True)\n",
    "\n",
    "\n",
    "# X = df[['main_okved', 'region_code', 'company_type']]\n",
    "#y = df['target']\n",
    "\n",
    "#model = CatBoostClassifier(iterations=100, verbose=False)\n",
    "#cat_features = [0,1,2] # все признаки категориальные\n",
    "\n",
    "#X.drop(edges[edges['id_2'] == i].id_1.values, inplace=True)\n",
    "#X.drop(edges[edges['id_1'] == i].id_2.values, inplace=True)\n",
    "#df.drop(edges[edges['id_2'] == i].id_1.values, inplace=True)\n",
    "#df.drop(edges[edges['id_1'] == i].id_2.values, inplace=True)\n",
    "\n",
    "\n",
    "df['preds'] = preds\n",
    "df['id_2'] = ids.id.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='preds', ascending=False).iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(ids.id,errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=['id_1', 'id_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(ids.id):\n",
    "    df1 = edges[edges['id_1'] == i].reset_index()\n",
    "    df2 = edges[edges['id_2'] == i].reset_index()\n",
    "\n",
    "    df = df1[['id_2', 'id_1']].rename(columns={'id_1':'id_2', 'id_2':'id_1'}).append(df2[['id_1', 'id_2']])\n",
    "    df['target'] = 1\n",
    "\n",
    "    df = vertices.join(df.set_index('id_1')['target']).fillna(0)\n",
    "    df['id_1']=df.index\n",
    "    df.drop(ids.id.values, errors='ignore',inplace=True)\n",
    "   \n",
    "    X = df[['main_okved', 'region_code', 'company_type','degree','1_nearest_neigbour','2_nearest_neigbour','3_nearest_neigbour','4_nearest_neigbour']]\n",
    "    y = df['target']\n",
    "    model = CatBoostClassifier(task_type='GPU',iterations=100, verbose=False)\n",
    "    model.fit(X, y)\n",
    "    preds = model.predict_proba(X)[:,1]\n",
    "    df['preds'] = preds\n",
    "    df['id_2'] = i\n",
    "\n",
    "    # возьмем первую 1000 предсказанных ребер, исключив те, про которые мы уже знали\n",
    "    res = df[(df['target'] != 1) & (df.index!=i)].sort_values(by='preds', ascending=False).iloc[:1000]\n",
    "    res.columns = ['df1','main_okved', 'region_code', 'company_type','degree','1_nearest_neigbour','2_nearest_neigbour','3_nearest_neigbour','4_nearest_neigbour', 'target','prob','id_2']\n",
    "    \n",
    "\n",
    "    result = result.append(res, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edges['id_1'] = edges['id_1'].astype(str)\n",
    "#edges['id_2'] = edges['id_2'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids.id.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm.tqdm(ids.id):\n",
    "    statistics.append([i,len(edges[edges['id_1'] == i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot(2,1,1)\n",
    "plt.hist(edges.n_transactions)\n",
    "plt.title(\"Распределение количества транзакций\")\n",
    "plt.subplot(2,1,2)\n",
    "plt.hist(edges.value)\n",
    "plt.title(\"Распределение сумм транзакций\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = edges.iloc[:,[0,2,3]]\n",
    "y = edges.iloc[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model whole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding new features\n",
    "* graph (degree)\n",
    "* оквед_1, оквед_2\n",
    "* метомодель\n",
    "* KNN (номер кластера)\n",
    "* близжайшие соседи\n",
    "* кратчайшие пути"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CatBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = edges[edges['id_1'] == ids.id.iloc[0]].reset_index()\n",
    "df2 = edges[edges['id_2'] == ids.id.iloc[0]].reset_index()\n",
    "\n",
    "df = df1[['id_2', 'id_1']].rename(columns={'id_1':'id_2', 'id_2':'id_1'}).append(df2[['id_1', 'id_2']])\n",
    "df['target'] = 1\n",
    "\n",
    "df = vertices.set_index('id').join(df.set_index('id_1')['target']).fillna(0)\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['company_type'] = le.fit_transform(df['company_type'])\n",
    "df['main_okved'] = le.fit_transform(df['main_okved'])\n",
    "\n",
    "#Degree\n",
    "errors = []\n",
    "degrees = []\n",
    "for j in df.index:\n",
    "    try:\n",
    "        degrees.append([j,g.nodes[j]['degree']])\n",
    "    except:\n",
    "    #print('Error',i)\n",
    "        errors.append(j)\n",
    "\n",
    "degree = pd.DataFrame(degrees, columns=['id','degree'])\n",
    "degree.set_index('id', inplace=True)\n",
    "df = df.merge(degree, how='inner', on='id')\n",
    "\n",
    "#KNN\n",
    "#nbrs = NearestNeighbors(n_neighbors=4, algorithm='kd_tree', n_jobs=4).fit(df[['main_okved','region_code','company_type','degree']].to_numpy())\n",
    "#distances, indices = nbrs.kneighbors(df[['main_okved','region_code','company_type','degree']].to_numpy())\n",
    "#df['1_nearest_neigbour'] = [indices[r][0] for r in range(len(df.index))]\n",
    "#df['2_nearest_neigbour'] = [indices[r][1] for r in range(len(df.index))]\n",
    "#df['3_nearest_neigbour'] = [indices[r][2] for r in range(len(df.index))]\n",
    "#df['4_nearest_neigbour'] = [indices[r][3] for r in range(len(df.index))]\n",
    "\n",
    "X = df[['main_okved', 'region_code', 'company_type','degree','1_nearest_neigbour','4_nearest_neigbour','2_nearest_neigbour','3_nearest_neigbour']]\n",
    "y = df['target']\n",
    "model = CatBoostClassifier(task_type='GPU',iterations=100, verbose=False)\n",
    "cat_features = [0,1,2,4,5,6,7] \n",
    "\n",
    "# X = df[['main_okved', 'region_code', 'company_type']]\n",
    "#y = df['target']\n",
    "\n",
    "#model = CatBoostClassifier(iterations=100, verbose=False)\n",
    "#cat_features = [0,1,2] # все признаки категориальные\n",
    "\n",
    "model.fit(X, y, cat_features)\n",
    "\n",
    "preds = model.predict_proba(X)[:,1]\n",
    "\n",
    "df['preds'] = preds\n",
    "df['id_2'] = ids.id.iloc[0]\n",
    "\n",
    "# возьмем первую 1000 предсказанных ребер, исключив те, про которые мы уже знали\n",
    "res = df[df['target'] != 1].sort_values(by='preds', ascending=False).iloc[:1000].reset_index()[['id', 'id_2']]\n",
    "res.columns = ['id_1', 'id_2']\n",
    "\n",
    "result = result.append(res, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = edges[edges['id_1'] == ids.id.iloc[0]].reset_index()\n",
    "df2 = edges[edges['id_2'] == ids.id.iloc[0]].reset_index()\n",
    "\n",
    "df = df1[['id_2', 'id_1']].rename(columns={'id_1':'id_2', 'id_2':'id_1'}).append(df2[['id_1', 'id_2']])\n",
    "df['target'] = 1\n",
    "\n",
    "df = vertices.set_index('id').join(df.set_index('id_1')['target']).fillna(0)\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['company_type'] = le.fit_transform(df['company_type'])\n",
    "df['main_okved'] = le.fit_transform(df['main_okved'])\n",
    "df['main_okved'] = le.fit_transform(df['main_okved'])\n",
    "\n",
    "#Degree\n",
    "errors = []\n",
    "degrees = []\n",
    "for j in df.index:\n",
    "    try:\n",
    "        degrees.append([j,g.nodes[j]['degree']])\n",
    "    except:\n",
    "    #print('Error',i)\n",
    "        errors.append(j)\n",
    "\n",
    "degree = pd.DataFrame(degrees, columns=['id','degree'])\n",
    "degree.set_index('id', inplace=True)\n",
    "df = df.merge(degree, how='inner', on='id')\n",
    "\n",
    "#KNN\n",
    "#nbrs = NearestNeighbors(n_neighbors=4, algorithm='kd_tree', n_jobs=4).fit(df[['main_okved','region_code','company_type','degree']].to_numpy())\n",
    "#distances, indices = nbrs.kneighbors(df[['main_okved','region_code','company_type','degree']].to_numpy())\n",
    "#df['1_nearest_neigbour'] = [indices[r][0] for r in range(len(df.index))]\n",
    "#df['2_nearest_neigbour'] = [indices[r][1] for r in range(len(df.index))]\n",
    "#df['3_nearest_neigbour'] = [indices[r][2] for r in range(len(df.index))]\n",
    "#df['4_nearest_neigbour'] = [indices[r][3] for r in range(len(df.index))]\n",
    "\n",
    "X = df[['main_okved', 'region_code', 'company_type','degree']]\n",
    "y = df['target']\n",
    "model = CatBoostClassifier(task_type='GPU',iterations=100, verbose=False)\n",
    "cat_features = [0,1,2] \n",
    "\n",
    "# X = df[['main_okved', 'region_code', 'company_type']]\n",
    "#y = df['target']\n",
    "\n",
    "#model = CatBoostClassifier(iterations=100, verbose=False)\n",
    "#cat_features = [0,1,2] # все признаки категориальные\n",
    "\n",
    "model.fit(X, y, cat_features)\n",
    "\n",
    "preds = model.predict_proba(X)[:,1]\n",
    "\n",
    "df['preds'] = preds\n",
    "df['id_2'] = ids.id.iloc[0]\n",
    "\n",
    "# возьмем первую 1000 предсказанных ребер, исключив те, про которые мы уже знали\n",
    "res = df[df['target'] != 1].sort_values(by='preds', ascending=False).iloc[:1000].reset_index()[['id', 'id_2']]\n",
    "res.columns = ['id_1', 'id_2']\n",
    "\n",
    "result = result.append(res, ignore_index=True, sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=['id_1', 'id_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(ids.id):\n",
    "    df1 = edges[edges['id_1'] == i].reset_index()\n",
    "    df2 = edges[edges['id_2'] == i].reset_index()\n",
    "\n",
    "    df = df1[['id_2', 'id_1']].rename(columns={'id_1':'id_2', 'id_2':'id_1'}).append(df2[['id_1', 'id_2']])\n",
    "    df['target'] = 1\n",
    "\n",
    "    df = vertices.set_index('id').join(df.set_index('id_1')['target']).fillna(0)\n",
    "    #from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    #df['company_type'] = le.fit_transform(df['company_type'])\n",
    "    #df['main_okved'] = le.fit_transform(df['main_okved'])\n",
    "    \n",
    "    #Degree\n",
    "    errors = []\n",
    "    degrees = []\n",
    "    for j in tqdm(df.index):\n",
    "        try:\n",
    "            degrees.append([j,g.nodes[j]['degree']])\n",
    "        except:\n",
    "        #print('Error',i)\n",
    "            errors.append(j)\n",
    "\n",
    "    degree = pd.DataFrame(degrees, columns=['id','degree'])\n",
    "    degree.set_index('id', inplace=True)\n",
    "    df = df.merge(degree, how='inner', on='id')\n",
    "    df.drop(ids.id.values, inplace=True)\n",
    "\n",
    "    #KNN\n",
    "    #nbrs = NearestNeighbors(n_neighbors=4, algorithm='kd_tree', n_jobs=4).fit(df[['main_okved','region_code','company_type','degree']].to_numpy())\n",
    "    #distances, indices = nbrs.kneighbors(df[['main_okved','region_code','company_type','degree']].to_numpy())\n",
    "    #df['1_nearest_neigbour'] = [indices[r][0] for r in range(len(df.index))]\n",
    "    #df['2_nearest_neigbour'] = [indices[r][1] for r in range(len(df.index))]\n",
    "    #df['3_nearest_neigbour'] = [indices[r][2] for r in range(len(df.index))]\n",
    "    #df['4_nearest_neigbour'] = [indices[r][3] for r in range(len(df.index))]\n",
    "\n",
    "    X = df[['main_okved', 'region_code', 'company_type','degree']]\n",
    "    y = df['target']\n",
    "    model = CatBoostClassifier(task_type='GPU',iterations=100, verbose=False)\n",
    "    cat_features = [0,1,2] \n",
    "\n",
    "    # X = df[['main_okved', 'region_code', 'company_type']]\n",
    "    #y = df['target']\n",
    "\n",
    "    #model = CatBoostClassifier(iterations=100, verbose=False)\n",
    "    #cat_features = [0,1,2] # все признаки категориальные\n",
    "\n",
    "    model.fit(X, y, cat_features)\n",
    "    #X.drop(edges[edges['id_2'] == i].id_1.values, inplace=True)\n",
    "    #X.drop(edges[edges['id_1'] == i].id_2.values, inplace=True)\n",
    "\n",
    "    preds = model.predict_proba(X)[:,1]\n",
    "    #df.drop(edges[edges['id_2'] == i].id_1.values, inplace=True)\n",
    "    #df.drop(edges[edges['id_1'] == i].id_2.values, inplace=True)\n",
    "\n",
    "\n",
    "    df['preds'] = preds\n",
    "    df['id_2'] = i\n",
    "    #df['prob'] = model.predict_proba(X)[:,0]\n",
    "\n",
    "    # возьмем первую 1000 предсказанных ребер, исключив те, про которые мы уже знали\n",
    "    #res['prob'] = model.predict_proba(X)[:,0]\n",
    "    res = df[(df['target'] != 1) & (df.index!=i)].sort_values(by='preds', ascending=False).iloc[:1000].reset_index()[['id', 'id_2']]\n",
    "    res.columns = ['id_1', 'id_2']\n",
    "    \n",
    "\n",
    "    result = result.append(res, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(X)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"preds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result.to_csv('/Private/result1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Iteration Disambl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = edges[edges['id_1'] == ids.id.iloc[0]].reset_index()\n",
    "df2 = edges[edges['id_2'] == ids.id.iloc[0]].reset_index()\n",
    "\n",
    "df = df1[['id_2', 'id_1']].rename(columns={'id_1':'id_2', 'id_2':'id_1'}).append(df2[['id_1', 'id_2']])\n",
    "df['target'] = 1\n",
    "\n",
    "df = vertices.set_index('id').join(df.set_index('id_1')['target']).fillna(0)\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "#df['company_type'] = le.fit_transform(df['company_type'])\n",
    "#df['main_okved'] = le.fit_transform(df['main_okved'])\n",
    "#df['main_okved'] = le.fit_transform(df['main_okved'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "degrees = []\n",
    "for i in tqdm(df.index):\n",
    "    try:\n",
    "        degrees.append([i,g.nodes[i]['degree']])\n",
    "    except:\n",
    "        #print('Error',i)\n",
    "        errors.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = pd.DataFrame(degrees, columns=['id','degree'])\n",
    "degree.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(['degree'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = pd.DataFrame(degrees, columns=['id','degree'])\n",
    "degree.set_index('id', inplace=True)\n",
    "df = df.merge(degree, how='inner', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['main_okved'] = df['main_okved'].astype(str)\n",
    "df['company_type'] = df['company_type'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time nbrs = NearestNeighbors(n_neighbors=2, algorithm='kd_tree', n_jobs=4).fit(df[['main_okved','region_code','company_type','degree']].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = nbrs.kneighbors(df[['main_okved','region_code','company_type','degree']].to_numpy())\n",
    "df['1_nearest_neigbour'] = [indices[i][0] for i in range(len(df.index))]\n",
    "df['2_nearest_neigbour'] = [indices[i][1] for i in range(len(df.index))]\n",
    "df['3_nearest_neigbour'] = [indices[i][2] for i in range(len(df.index))]\n",
    "df['4_nearest_neigbour'] = [indices[i][3] for i in range(len(df.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=['id_1', 'id_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['main_okved', 'region_code', 'company_type','degree','1_nearest_neigbour','4_nearest_neigbour','2_nearest_neigbour','3_nearest_neigbour']]\n",
    "y = df['target']\n",
    "model = CatBoostClassifier(task_type='GPU',iterations=100, verbose=False)\n",
    "cat_features = [0,1,2] \n",
    "\n",
    "# X = df[['main_okved', 'region_code', 'company_type']]\n",
    "#y = df['target']\n",
    "\n",
    "#model = CatBoostClassifier(iterations=100, verbose=False)\n",
    "#cat_features = [0,1,2] # все признаки категориальные\n",
    "\n",
    "model.fit(X, y, cat_features)\n",
    "\n",
    "preds = model.predict_proba(X)[:,1]\n",
    "\n",
    "df['preds'] = preds\n",
    "df['id_2'] = ids.id.iloc[0]\n",
    "\n",
    "# возьмем первую 1000 предсказанных ребер, исключив те, про которые мы уже знали\n",
    "res = df[df['target'] != 1].sort_values(by='preds', ascending=False).iloc[:1000].reset_index()[['id', 'id_2']]\n",
    "res.columns = ['id_1', 'id_2']\n",
    "\n",
    "result = result.append(res, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means. No K-Means. Long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=['id_1', 'id_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(ids.id):\n",
    "    # соберем датасет из всех возможных вершин\n",
    "    # вершины имеющие в исходных данных ребро с i обозначим 1, остальные 0\n",
    "    # учтем то, что вершина i может быть как среди id_1, так и среди id_2\n",
    "    df1 = edges[edges['id_1'] == i].reset_index()\n",
    "    df2 = edges[edges['id_2'] == i].reset_index()\n",
    "    \n",
    "\n",
    "    df = df1[['id_2', 'id_1']].rename(columns={'id_1':'id_2', 'id_2':'id_1'}).append(df2[['id_1', 'id_2']])\n",
    "    df['target'] = 1\n",
    "    \n",
    "    df = vertices.set_index('id').join(df.set_index('id_1')['target']).fillna(0)\n",
    "    #from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    df['company_type'] = le.fit_transform(df['company_type'])\n",
    "    df['main_okved'] = le.fit_transform(df['main_okved'])\n",
    "    #Degree\n",
    "    errors = []\n",
    "    degrees = []\n",
    "    for j in tqdm(df.index):\n",
    "        try:\n",
    "            degrees.append([j,g.nodes[j]['degree']])\n",
    "        except:\n",
    "        #print('Error',i)\n",
    "            errors.append(j)\n",
    "    \n",
    "    degree = pd.DataFrame(degrees, columns=['id','degree'])\n",
    "    degree.set_index('id', inplace=True)\n",
    "    df = df.merge(degree, how='inner', on='id')\n",
    "    #KNN\n",
    "    nbrs = NearestNeighbors(n_neighbors=4, algorithm='kd_tree', n_jobs=4).fit(df.to_numpy())\n",
    "    distances, indices = nbrs.kneighbors(df.to_numpy())\n",
    "    df['1_nearest_neigbour'] = [indices[r][0] for r in range(len(df.index))]\n",
    "    df['2_nearest_neigbour'] = [indices[r][1] for r in range(len(df.index))]\n",
    "    df['3_nearest_neigbour'] = [indices[r][2] for r in range(len(df.index))]\n",
    "    df['4_nearest_neigbour'] = [indices[r][3] for r in range(len(df.index))]\n",
    "    \n",
    "    X = df[['main_okved', 'region_code', 'company_type','degree','1_nearest_neigbour','4_nearest_neigbour','2_nearest_neigbour','3_nearest_neigbour']]\n",
    "    y = df['target']\n",
    "    model = CatBoostClassifier(task_type='GPU',iterations=100, verbose=False)\n",
    "    cat_features = [0,1,2,4,5,6,7] \n",
    "    \n",
    "   # X = df[['main_okved', 'region_code', 'company_type']]\n",
    "    #y = df['target']\n",
    "    \n",
    "    #model = CatBoostClassifier(iterations=100, verbose=False)\n",
    "    #cat_features = [0,1,2] # все признаки категориальные\n",
    "    \n",
    "    model.fit(X, y, cat_features)\n",
    "\n",
    "    preds = model.predict_proba(X)[:,1]\n",
    "\n",
    "    df['preds'] = preds\n",
    "    df['id_2'] = i\n",
    "    \n",
    "    # возьмем первую 1000 предсказанных ребер, исключив те, про которые мы уже знали\n",
    "    res = df[df['target'] != 1].sort_values(by='preds', ascending=False).iloc[:1000].reset_index()[['id', 'id_2']]\n",
    "    res.columns = ['id_1', 'id_2']\n",
    "    \n",
    "    result = result.append(res, ignore_index=True, sort=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
